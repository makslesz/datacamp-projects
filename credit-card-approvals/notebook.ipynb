{"cells":[{"cell_type":"code","execution_count":null,"id":"9a4e8c8f","metadata":{"dc":{"key":"3"},"tags":["sample_code"]},"outputs":[],"source":["# Import pandas\n","import pandas as pd\n","\n","# Load dataset\n","cc_apps = pd.read_csv(\"datasets/cc_approvals.data\", header=None)\n","\n","# Inspect data\n","cc_apps.head()"]},{"cell_type":"markdown","id":"a7158610","metadata":{"dc":{"key":"10"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 2. Inspecting the applications"]},{"cell_type":"code","execution_count":null,"id":"06a55b82","metadata":{"dc":{"key":"10"},"tags":["sample_code"]},"outputs":[],"source":["# Print summary statistics\n","cc_apps_description = cc_apps.describe()\n","print(cc_apps_description)\n","\n","print('\\n')\n","\n","# Print DataFrame information\n","cc_apps_info = cc_apps.info()\n","print(cc_apps_info)\n","\n","print('\\n')\n","\n","# Inspect missing values in the dataset\n","cc_apps.tail(17)"]},{"cell_type":"markdown","id":"09c45e23","metadata":{"dc":{"key":"17"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 3. Splitting the dataset into train and test sets"]},{"cell_type":"code","execution_count":null,"id":"90b45c5e","metadata":{"dc":{"key":"17"},"tags":["sample_code"]},"outputs":[],"source":["# Import train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","# Drop the features 11 and 13\n","cc_apps = cc_apps.drop([11, 13], axis=1)\n","\n","# Split into train and test sets\n","cc_apps_train, cc_apps_test = train_test_split(cc_apps, test_size=0.33, random_state=42)"]},{"cell_type":"markdown","id":"bb9517cd","metadata":{"dc":{"key":"24"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 4. Handling the missing values (part I)"]},{"cell_type":"code","execution_count":null,"id":"615f5a9c","metadata":{"collapsed":true,"dc":{"key":"24"},"jupyter":{"outputs_hidden":true},"tags":["sample_code"]},"outputs":[],"source":["# Import numpy\n","import numpy as np\n","\n","# Replace the '?'s with NaN in the train and test sets\n","cc_apps_train = cc_apps_train.replace('?', np.NaN)\n","cc_apps_test = cc_apps_test.replace('?', np.NaN)"]},{"cell_type":"markdown","id":"9b7fb5ec","metadata":{"dc":{"key":"31"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 5. Handling the missing values (part II)"]},{"cell_type":"code","execution_count":null,"id":"02034413","metadata":{"dc":{"key":"31"},"tags":["sample_code"]},"outputs":[],"source":["# Impute the missing values with mean imputation\n","cc_apps_train.fillna(cc_apps_train.mean(), inplace=True)\n","cc_apps_test.fillna(cc_apps_train.mean(), inplace=True)\n","\n","# Count the number of NaNs in the datasets and print the counts to verify\n","print(cc_apps_train.isnull().sum())\n","print(cc_apps_test.isnull().sum())"]},{"cell_type":"markdown","id":"57b6a807","metadata":{"dc":{"key":"38"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 6. Handling the missing values (part III)"]},{"cell_type":"code","execution_count":null,"id":"9d6b4c7f","metadata":{"dc":{"key":"38"},"tags":["sample_code"]},"outputs":[],"source":["# Iterate over each column of cc_apps_train\n","for col in cc_apps_train.columns:\n","    # Check if the column is of object type\n","    if cc_apps_train[col].dtypes == 'object':\n","        # Impute with the most frequent value\n","        cc_apps_train = cc_apps_train.fillna(cc_apps_train[col].value_counts().index[0])\n","        cc_apps_test = cc_apps_test.fillna(cc_apps_train[col].value_counts().index[0])\n","\n","# Count the number of NaNs in the dataset and print the counts to verify\n","print(cc_apps_train.isnull().sum())\n","print(cc_apps_test.isnull().sum())"]},{"cell_type":"markdown","id":"1b91d62f","metadata":{"dc":{"key":"45"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 7. Preprocessing the data (part I)"]},{"cell_type":"code","execution_count":null,"id":"008581fc","metadata":{"dc":{"key":"45"},"tags":["sample_code"]},"outputs":[],"source":["# Convert the categorical features in the train and test sets independently\n","cc_apps_train = pd.get_dummies(cc_apps_train)\n","cc_apps_test = pd.get_dummies(cc_apps_test)\n","\n","# Reindex the columns of the test set aligning with the train set\n","cc_apps_test = cc_apps_test.reindex(columns=cc_apps_train.columns, fill_value=0)"]},{"cell_type":"markdown","id":"67981bb7","metadata":{"dc":{"key":"52"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 8. Preprocessing the data (part II)"]},{"cell_type":"code","execution_count":null,"id":"16a4a9e5","metadata":{"dc":{"key":"52"},"tags":["sample_code"]},"outputs":[],"source":["# Import MinMaxScaler\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Segregate features and labels into separate variables\n","X_train, y_train = cc_apps_train.iloc[:, :-1].values, cc_apps_train.iloc[:, [-1]].values\n","X_test, y_test = cc_apps_test.iloc[:, :-1].values, cc_apps_test.iloc[:, [-1]].values\n","\n","# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","rescaledX_train = scaler.fit_transform(X_train)\n","rescaledX_test = scaler.transform(X_test)"]},{"cell_type":"markdown","id":"c2731c8e","metadata":{"dc":{"key":"59"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 9. Fitting a logistic regression model to the train set"]},{"cell_type":"code","execution_count":null,"id":"60d22ab2","metadata":{"dc":{"key":"59"},"tags":["sample_code"]},"outputs":[],"source":["# Import LogisticRegression\n","from sklearn.linear_model import LogisticRegression\n","\n","# Instantiate a LogisticRegression classifier with default parameter values\n","logreg = LogisticRegression()\n","\n","# Fit logreg to the train set\n","logreg.fit(rescaledX_train, y_train)"]},{"cell_type":"markdown","id":"9cd197d3","metadata":{"dc":{"key":"66"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 10. Making predictions and evaluating performance"]},{"cell_type":"code","execution_count":null,"id":"fa6bf690","metadata":{"dc":{"key":"66"},"tags":["sample_code"]},"outputs":[],"source":["# Import confusion_matrix\n","from sklearn.metrics import confusion_matrix\n","\n","# Use logreg to predict instances from the test set and store it\n","y_pred = logreg.predict(rescaledX_test)\n","\n","# Get the accuracy score of logreg model and print it\n","print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test, y_test))\n","\n","# Print the confusion matrix of the logreg model\n","print(confusion_matrix(y_test, y_pred))"]},{"cell_type":"markdown","id":"9fabd03e","metadata":{"dc":{"key":"73"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 11. Grid searching and making the model perform better"]},{"cell_type":"code","execution_count":null,"id":"6587303d","metadata":{"dc":{"key":"73"},"tags":["sample_code"]},"outputs":[],"source":["# Import GridSearchCV\n","from sklearn.model_selection import GridSearchCV\n","\n","# Define the grid of values for tol and max_iter\n","tol = [0.01, 0.001, 0.0001]\n","max_iter = [100, 150, 200]\n","\n","# Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\n","param_grid = {'tol':tol, 'max_iter':max_iter}"]},{"cell_type":"markdown","id":"8445a063","metadata":{"dc":{"key":"80"},"deletable":false,"editable":false,"run_control":{"frozen":true},"tags":["context"]},"source":["## 12. Finding the best performing model"]},{"cell_type":"code","execution_count":null,"id":"373f0242","metadata":{"dc":{"key":"80"},"tags":["sample_code"]},"outputs":[],"source":["# Instantiate GridSearchCV with the required parameters\n","grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n","\n","# Fit grid_model to the data\n","grid_model_result = grid_model.fit(rescaledX_train, y_train)\n","\n","# Summarize results\n","best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n","print(\"Best: %f using %s\" % (best_score, best_params))\n","\n","# Extract the best model and evaluate it on the test set\n","best_model = grid_model_result.best_estimator_\n","print(\"Accuracy of logistic regression classifier: \", best_model.score(rescaledX_test, y_test))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":5}
